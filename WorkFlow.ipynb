{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOB Description Scraper from Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobDescriptionScraper import LinkedInDescriptionScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedIndescriptionCollector = LinkedInDescriptionScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = 3967809738"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PdfLoader import loadPdfContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = loadPdfContent(r\"C:\\Users\\mnsnn\\Documents\\AI\\AI Products\\ReGen\\src\\regen\\ResumeGen\\Generated Resume.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Score Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResumeValidator import ValidateResume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_score_validator = ValidateResume()\n",
    "scores = resume_score_validator.get_resume_scores(resume, job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Keyword_Matching_Score': '75',\n",
       " 'Skills_Matching_Score': '70',\n",
       " 'Qualifications_Matching_Score': '65',\n",
       " 'Experience_Alignment_Score': '60',\n",
       " 'Education_and_Certifications_Alignment_Score': '80',\n",
       " 'Soft_Skills_and_Personal_Attributes_Score': '65',\n",
       " 'Overall_Fit_Score': '69'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume JOSN Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResumeJsonGen import generateResumeJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_json = generateResumeJson(resume, job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume PDF Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumePdfGenerator import newResumePdfGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumeGenStatus = newResumePdfGenerator(resume_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumeGenStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Job Listings Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up options for running Edge browser in headless mode\n",
    "options = Options()\n",
    "options.use_chromium = True\n",
    "# options.add_argument(\"--headless\")\n",
    "\n",
    "# Set up Edge WebDriver service\n",
    "service = Service(executable_path=EdgeChromiumDriverManager().install())\n",
    "# Initialize Edge WebDriver instance\n",
    "driver = webdriver.Edge(service=service, options=options)\n",
    "# Set up WebDriverWait with a timeout of 10 seconds\n",
    "wait = WebDriverWait(driver, 10)\n",
    "# Maximize the browser window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def generate_linkedin_url(job_title, location, position=1, page_num=0):\n",
    "    \"\"\"\n",
    "    Generate the LinkedIn job search URL for the given parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    job_title (str): The title of the job to search for.\n",
    "    location (str): The location to search for jobs.\n",
    "    geo_id (str): The geo ID for the location (default is for India).\n",
    "    position (int): The position of the job listing on the page.\n",
    "    page_num (int): The page number to retrieve results from.\n",
    "    \n",
    "    Returns:\n",
    "    str: The constructed LinkedIn job search URL.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.linkedin.com/jobs/search?\"\n",
    "    \n",
    "    params = {\n",
    "        \"keywords\": job_title,\n",
    "        \"location\": location,\n",
    "        \"trk\": \"public_jobs_jobs-search-bar_search-submit\",\n",
    "        \"position\": position,\n",
    "        \"pageNum\": page_num\n",
    "    }\n",
    "    \n",
    "    full_url = base_url + urllib.parse.urlencode(params)\n",
    "    return full_url\n",
    "\n",
    "def fetch_job_listings(driver, linkedin_url):\n",
    "    \"\"\"\n",
    "    Fetch job listings from LinkedIn job search page.\n",
    "    \n",
    "    Parameters:\n",
    "    driver (WebDriver): The Selenium WebDriver instance.\n",
    "    linkedin_url (str): The LinkedIn job search URL to visit.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of Selenium web elements representing job listings.\n",
    "    \"\"\"\n",
    "    driver.get(linkedin_url)\n",
    "    table = driver.find_element(By.CLASS_NAME, 'jobs-search__results-list')\n",
    "    jobs = table.find_elements(By.TAG_NAME, 'li')\n",
    "    return jobs\n",
    "\n",
    "def parse_job_data(job):\n",
    "    \"\"\"\n",
    "    Extract job data from a single job listing element.\n",
    "    \n",
    "    Parameters:\n",
    "    job (WebElement): The Selenium WebElement representing a job listing.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the job details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        job_dict = {\n",
    "            'Job Title': job.find_element(By.CLASS_NAME, 'base-search-card__title').text,\n",
    "            'Company Name': job.find_element(By.CLASS_NAME, 'base-search-card__subtitle').text,\n",
    "            'Company URL': job.find_element(By.CLASS_NAME, 'hidden-nested-link').get_attribute('href'),\n",
    "            'Location': job.find_element(By.CLASS_NAME, 'job-search-card__location').text,\n",
    "            'Job Link': job.find_element(By.CLASS_NAME, 'base-card__full-link').get_attribute('href'),\n",
    "        }\n",
    "\n",
    "        # Extract the exact date from the time tag using the datetime attribute\n",
    "        try:\n",
    "            time_element = job.find_element(By.CLASS_NAME, 'job-search-card__listdate')\n",
    "            job_dict['Date Posted'] = time_element.get_attribute('datetime')  # Extract exact date in YYYY-MM-DD\n",
    "        except:\n",
    "            job_dict['Date Posted'] = None  # If not found, set as None\n",
    "\n",
    "        # Check for job benefits, like \"Actively Hiring\"\n",
    "        try:\n",
    "            job_dict['Benefits'] = job.find_element(By.CLASS_NAME, 'job-posting-benefits__text').text\n",
    "        except:\n",
    "            job_dict['Benefits'] = None  # If not found, set as None\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle case where some elements may be missing\n",
    "        job_dict = {\n",
    "            'Job Title': None,\n",
    "            'Company Name': None,\n",
    "            'Company URL': None,\n",
    "            'Location': None,\n",
    "            'Job Link': None,\n",
    "            'Date Posted': None,\n",
    "            'Benefits': None\n",
    "        }\n",
    "    \n",
    "    return job_dict\n",
    "\n",
    "\n",
    "def get_jobs_data(jobs):\n",
    "    \"\"\"\n",
    "    Collect job data from a list of job listing elements.\n",
    "    \n",
    "    Parameters:\n",
    "    jobs (list): A list of Selenium WebElements representing job listings.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the job details.\n",
    "    \"\"\"\n",
    "    jobs_data = [parse_job_data(job) for job in jobs]\n",
    "    return pd.DataFrame(jobs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m linkedin_url \u001b[38;5;241m=\u001b[39m generate_linkedin_url(job_title, location)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming 'driver' is a Selenium WebDriver instance\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m jobs \u001b[38;5;241m=\u001b[39m fetch_job_listings(\u001b[43mdriver\u001b[49m, linkedin_url)\n\u001b[0;32m      8\u001b[0m jobs_df \u001b[38;5;241m=\u001b[39m get_jobs_data(jobs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "job_title = \"Data Scientist\"\n",
    "location = \"Trivandrum, Kerala, India\"\n",
    "linkedin_url = generate_linkedin_url(job_title, location)\n",
    "\n",
    "# Assuming 'driver' is a Selenium WebDriver instance\n",
    "jobs = fetch_job_listings(driver, linkedin_url)\n",
    "jobs_df = get_jobs_data(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def generate_linkedin_url(job_title, location, position=1, page_num=0):\n",
    "    \"\"\"\n",
    "    Generate the LinkedIn job search URL for the given parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    job_title (str): The title of the job to search for.\n",
    "    location (str): The location to search for jobs.\n",
    "    position (int): The position of the job listing on the page.\n",
    "    page_num (int): The page number to retrieve results from.\n",
    "    \n",
    "    Returns:\n",
    "    str: The constructed LinkedIn job search URL.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.linkedin.com/jobs/search?\"\n",
    "    \n",
    "    params = {\n",
    "        \"keywords\": job_title,\n",
    "        \"location\": location,\n",
    "        \"trk\": \"public_jobs_jobs-search-bar_search-submit\",\n",
    "        \"position\": position,\n",
    "        \"pageNum\": page_num\n",
    "    }\n",
    "    \n",
    "    full_url = base_url + urllib.parse.urlencode(params)\n",
    "    return full_url\n",
    "\n",
    "def fetch_job_listings(driver, linkedin_url):\n",
    "    \"\"\"\n",
    "    Fetch job listings from LinkedIn job search page.\n",
    "    \n",
    "    Parameters:\n",
    "    driver (WebDriver): The Selenium WebDriver instance.\n",
    "    linkedin_url (str): The LinkedIn job search URL to visit.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of Selenium web elements representing job listings.\n",
    "    \"\"\"\n",
    "    driver.get(linkedin_url)\n",
    "    table = driver.find_element(By.CLASS_NAME, 'jobs-search__results-list')\n",
    "    jobs = table.find_elements(By.TAG_NAME, 'li')\n",
    "    return jobs\n",
    "\n",
    "def parse_job_data(job):\n",
    "    \"\"\"\n",
    "    Extract job data from a single job listing element.\n",
    "    \n",
    "    Parameters:\n",
    "    job (WebElement): The Selenium WebElement representing a job listing.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the job details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        job_dict = {\n",
    "            'Job Title': job.find_element(By.CLASS_NAME, 'base-search-card__title').text,\n",
    "            'Company Name': job.find_element(By.CLASS_NAME, 'base-search-card__subtitle').text,\n",
    "            'Company URL': job.find_element(By.CLASS_NAME, 'hidden-nested-link').get_attribute('href'),\n",
    "            'Location': job.find_element(By.CLASS_NAME, 'job-search-card__location').text,\n",
    "            'Job Link': job.find_element(By.CLASS_NAME, 'base-card__full-link').get_attribute('href'),\n",
    "        }\n",
    "\n",
    "        # Extract the exact date from the time tag using the datetime attribute\n",
    "        try:\n",
    "            time_element = job.find_element(By.CLASS_NAME, 'job-search-card__listdate')\n",
    "            job_dict['Date Posted'] = time_element.get_attribute('datetime')  # Extract exact date in YYYY-MM-DD\n",
    "        except:\n",
    "            job_dict['Date Posted'] = None  # If not found, set as None\n",
    "\n",
    "        # Check for job benefits, like \"Actively Hiring\"\n",
    "        try:\n",
    "            job_dict['Benefits'] = job.find_element(By.CLASS_NAME, 'job-posting-benefits__text').text\n",
    "        except:\n",
    "            job_dict['Benefits'] = None  # If not found, set as None\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle case where some elements may be missing\n",
    "        job_dict = {\n",
    "            'Job Title': None,\n",
    "            'Company Name': None,\n",
    "            'Company URL': None,\n",
    "            'Location': None,\n",
    "            'Job Link': None,\n",
    "            'Date Posted': None,\n",
    "            'Benefits': None\n",
    "        }\n",
    "    \n",
    "    return job_dict\n",
    "\n",
    "def get_jobs_data(jobs):\n",
    "    \"\"\"\n",
    "    Collect job data from a list of job listing elements.\n",
    "    \n",
    "    Parameters:\n",
    "    jobs (list): A list of Selenium WebElements representing job listings.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the job details.\n",
    "    \"\"\"\n",
    "    jobs_data = [parse_job_data(job) for job in jobs]\n",
    "    return pd.DataFrame(jobs_data)\n",
    "\n",
    "def scrape_linkedin_jobs(driver, job_title, location, num_results):\n",
    "    \"\"\"\n",
    "    Scrape LinkedIn job listings based on job title and location.\n",
    "    \n",
    "    Parameters:\n",
    "    driver (WebDriver): The Selenium WebDriver instance.\n",
    "    job_title (str): The title of the job to search for.\n",
    "    location (str): The location to search for jobs.\n",
    "    num_results (int): The number of job listings to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the job listings.\n",
    "    \"\"\"\n",
    "    jobs_per_page = 60\n",
    "    total_pages = (num_results // jobs_per_page) + 1  # Calculate how many pages we need to fetch\n",
    "    \n",
    "    all_jobs = []\n",
    "    \n",
    "    for page_num in range(total_pages):\n",
    "        linkedin_url = generate_linkedin_url(job_title, location, page_num=page_num)\n",
    "        jobs = fetch_job_listings(driver, linkedin_url)\n",
    "        all_jobs.extend(jobs)\n",
    "        \n",
    "        # If we've collected enough jobs, stop fetching more pages\n",
    "        if len(all_jobs) >= num_results:\n",
    "            break\n",
    "    \n",
    "    # Parse the job data\n",
    "    jobs_data = get_jobs_data(all_jobs[:num_results])  # Limit to the exact number of results requested\n",
    "    return jobs_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify job title, location, and number of results\n",
    "job_title = \"Data Scientist\"\n",
    "location = \"New York, NY\"\n",
    "num_results = 150  # Number of job listings to scrape\n",
    "\n",
    "# Scrape job listings\n",
    "jobs_data = scrape_linkedin_jobs(driver, job_title, location, num_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jobs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjobs_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jobs_df' is not defined"
     ]
    }
   ],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cookies\n",
    "import pickle\n",
    "pickle.dump(driver.get_cookies(), open(\"linkedincookies.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkedincookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multipage Cookie Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import urllib.parse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "def generate_linkedin_url(job_title, location, start):\n",
    "    base_url = \"https://www.linkedin.com/jobs/search?\"\n",
    "    params = {\n",
    "        \"keywords\": job_title,\n",
    "        \"location\": location,\n",
    "        \"refresh\": \"true\",\n",
    "        'start':start\n",
    "    }\n",
    "    full_url = base_url + urllib.parse.urlencode(params)\n",
    "    return full_url\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_job_listings(driver, linkedin_url):\n",
    "    driver.get(linkedin_url)\n",
    "    time.sleep(5)\n",
    "    table = driver.find_element(By.CLASS_NAME, 'scaffold-layout__list-container')\n",
    "    jobs = table.find_elements(By.TAG_NAME, 'li')\n",
    "    return jobs\n",
    "\n",
    "def parse_job_data(job):\n",
    "    div1 = job.find_element(By.TAG_NAME, 'div')\n",
    "    div2 = div1.find_element(By.TAG_NAME, 'div')\n",
    "    div3 = div2.find_elements(By.TAG_NAME, 'div')[0]\n",
    "    div4 = div3.find_element(By.CLASS_NAME, 'job-card-list__entity-lockup')\n",
    "    div5 = div4.find_element(By.CLASS_NAME, 'flex-grow-1')\n",
    "    title_div = div5.find_element(By.CLASS_NAME, 'artdeco-entity-lockup__title')\n",
    "    job_title_img = title_div.find_element(By.TAG_NAME, 'a')\n",
    "\n",
    "    job_title = job_title_img.text.split('\\n')[0]\n",
    "    job_link = job_title_img.get_attribute('href')\n",
    "    company_name = div5.find_element(By.CLASS_NAME, 'artdeco-entity-lockup__subtitle').text\n",
    "    job_location = div5.find_element(By.CLASS_NAME, 'artdeco-entity-lockup__caption').text\n",
    "\n",
    "    dct = {\n",
    "        'Job Title' : job_title,\n",
    "        'Job Post Url' : job_link,\n",
    "        'Company Name' : company_name,\n",
    "        'Location' : job_location\n",
    "    }\n",
    "\n",
    "    return dct\n",
    "\n",
    "def get_jobs_data(jobs):\n",
    "    lst = []\n",
    "    i = 0\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            job_dct = parse_job_data(job)\n",
    "            lst.append(job_dct)\n",
    "        except:\n",
    "            pass\n",
    "        print(i, ' Completed')\n",
    "        i += 1\n",
    "    return pd.DataFrame(lst)\n",
    "    \n",
    "\n",
    "def load_cookies(driver, cookies_file):\n",
    "    \"\"\"\n",
    "    Load cookies from a file and add them to the current session.\n",
    "    \n",
    "    Parameters:\n",
    "    driver (WebDriver): The Selenium WebDriver instance.\n",
    "    cookies_file (str): The path to the cookies file.\n",
    "    \"\"\"\n",
    "    driver.get(\"https://www.linkedin.com\")\n",
    "    with open(cookies_file, \"rb\") as file:\n",
    "        cookies = pickle.load(file)\n",
    "    for cookie in cookies:\n",
    "        driver.add_cookie(cookie)\n",
    "    driver.refresh()\n",
    "\n",
    "def scrape_linkedin_jobs(driver, job_title, location, num_results, cookies_file):\n",
    "    # Load cookies to log in\n",
    "    load_cookies(driver, cookies_file)\n",
    "    \n",
    "    num_pages = math.ceil(num_results / 25)\n",
    "    starts = [i*25 for i in range(num_pages)]\n",
    "    \n",
    "    all_jobs = []\n",
    "    \n",
    "    for start in starts:\n",
    "        print(f\"Scraping page\")\n",
    "        linkedin_url = generate_linkedin_url(job_title, location, start=start)\n",
    "        jobs = fetch_job_listings(driver, linkedin_url)\n",
    "        jobs_data = get_jobs_data(jobs)\n",
    "        display(jobs_data)\n",
    "        all_jobs.append(jobs_data)\n",
    "    \n",
    "    return pd.concat(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page\n",
      "0  Completed\n",
      "1  Completed\n",
      "2  Completed\n",
      "3  Completed\n",
      "4  Completed\n",
      "5  Completed\n",
      "6  Completed\n",
      "7  Completed\n",
      "8  Completed\n",
      "9  Completed\n",
      "10  Completed\n",
      "11  Completed\n",
      "12  Completed\n",
      "13  Completed\n",
      "14  Completed\n",
      "15  Completed\n",
      "16  Completed\n",
      "17  Completed\n",
      "18  Completed\n",
      "19  Completed\n",
      "20  Completed\n",
      "21  Completed\n",
      "22  Completed\n",
      "23  Completed\n",
      "24  Completed\n",
      "25  Completed\n",
      "26  Completed\n",
      "27  Completed\n",
      "28  Completed\n",
      "29  Completed\n",
      "30  Completed\n",
      "31  Completed\n",
      "32  Completed\n",
      "33  Completed\n",
      "34  Completed\n",
      "35  Completed\n",
      "36  Completed\n",
      "37  Completed\n",
      "38  Completed\n",
      "39  Completed\n",
      "40  Completed\n",
      "41  Completed\n",
      "42  Completed\n",
      "43  Completed\n",
      "44  Completed\n",
      "Scraping page\n",
      "0  Completed\n",
      "1  Completed\n",
      "2  Completed\n",
      "3  Completed\n",
      "4  Completed\n",
      "5  Completed\n",
      "6  Completed\n",
      "7  Completed\n",
      "8  Completed\n",
      "9  Completed\n",
      "10  Completed\n",
      "11  Completed\n",
      "12  Completed\n",
      "13  Completed\n",
      "14  Completed\n",
      "15  Completed\n",
      "16  Completed\n",
      "17  Completed\n",
      "18  Completed\n",
      "19  Completed\n",
      "20  Completed\n",
      "21  Completed\n",
      "22  Completed\n",
      "23  Completed\n",
      "24  Completed\n",
      "25  Completed\n",
      "26  Completed\n",
      "27  Completed\n",
      "28  Completed\n",
      "29  Completed\n",
      "30  Completed\n",
      "31  Completed\n",
      "32  Completed\n",
      "33  Completed\n",
      "34  Completed\n",
      "35  Completed\n",
      "36  Completed\n",
      "37  Completed\n",
      "38  Completed\n",
      "39  Completed\n",
      "40  Completed\n",
      "41  Completed\n",
      "42  Completed\n",
      "43  Completed\n",
      "44  Completed\n",
      "45  Completed\n",
      "46  Completed\n",
      "47  Completed\n",
      "Scraping page\n",
      "0  Completed\n",
      "1  Completed\n",
      "2  Completed\n",
      "3  Completed\n",
      "4  Completed\n",
      "5  Completed\n",
      "6  Completed\n",
      "7  Completed\n",
      "8  Completed\n",
      "9  Completed\n",
      "10  Completed\n",
      "11  Completed\n",
      "12  Completed\n",
      "13  Completed\n",
      "14  Completed\n",
      "15  Completed\n",
      "16  Completed\n",
      "17  Completed\n",
      "18  Completed\n",
      "19  Completed\n",
      "20  Completed\n",
      "21  Completed\n",
      "22  Completed\n",
      "23  Completed\n",
      "24  Completed\n",
      "25  Completed\n",
      "26  Completed\n",
      "27  Completed\n",
      "28  Completed\n",
      "29  Completed\n",
      "30  Completed\n",
      "31  Completed\n",
      "32  Completed\n",
      "33  Completed\n",
      "34  Completed\n",
      "35  Completed\n",
      "36  Completed\n",
      "37  Completed\n",
      "38  Completed\n",
      "39  Completed\n",
      "40  Completed\n",
      "41  Completed\n",
      "42  Completed\n",
      "43  Completed\n",
      "44  Completed\n",
      "45  Completed\n",
      "46  Completed\n",
      "Scraping page\n",
      "0  Completed\n",
      "1  Completed\n",
      "2  Completed\n",
      "3  Completed\n",
      "4  Completed\n",
      "5  Completed\n",
      "6  Completed\n",
      "7  Completed\n",
      "8  Completed\n",
      "9  Completed\n",
      "10  Completed\n",
      "11  Completed\n",
      "12  Completed\n",
      "13  Completed\n",
      "14  Completed\n",
      "15  Completed\n",
      "16  Completed\n",
      "17  Completed\n",
      "18  Completed\n",
      "19  Completed\n",
      "20  Completed\n",
      "21  Completed\n",
      "22  Completed\n",
      "23  Completed\n",
      "24  Completed\n",
      "25  Completed\n",
      "26  Completed\n",
      "27  Completed\n",
      "28  Completed\n",
      "29  Completed\n",
      "30  Completed\n",
      "31  Completed\n",
      "32  Completed\n",
      "33  Completed\n",
      "34  Completed\n",
      "35  Completed\n",
      "36  Completed\n",
      "37  Completed\n",
      "38  Completed\n",
      "39  Completed\n",
      "40  Completed\n",
      "41  Completed\n",
      "42  Completed\n",
      "43  Completed\n",
      "44  Completed\n",
      "Scraping page\n",
      "0  Completed\n",
      "1  Completed\n",
      "2  Completed\n",
      "3  Completed\n",
      "4  Completed\n",
      "5  Completed\n",
      "6  Completed\n",
      "7  Completed\n",
      "8  Completed\n",
      "9  Completed\n",
      "10  Completed\n",
      "11  Completed\n",
      "12  Completed\n",
      "13  Completed\n",
      "14  Completed\n",
      "15  Completed\n",
      "16  Completed\n",
      "17  Completed\n",
      "18  Completed\n",
      "19  Completed\n",
      "20  Completed\n",
      "21  Completed\n",
      "22  Completed\n",
      "23  Completed\n",
      "24  Completed\n",
      "25  Completed\n",
      "26  Completed\n",
      "27  Completed\n",
      "28  Completed\n",
      "29  Completed\n",
      "30  Completed\n",
      "31  Completed\n",
      "32  Completed\n",
      "33  Completed\n",
      "34  Completed\n",
      "35  Completed\n",
      "36  Completed\n",
      "37  Completed\n",
      "38  Completed\n",
      "39  Completed\n",
      "40  Completed\n",
      "41  Completed\n",
      "42  Completed\n",
      "43  Completed\n",
      "44  Completed\n",
      "45  Completed\n",
      "46  Completed\n",
      "Scraping page\n",
      "0  Completed\n",
      "1  Completed\n",
      "2  Completed\n",
      "3  Completed\n",
      "4  Completed\n",
      "5  Completed\n",
      "6  Completed\n",
      "7  Completed\n",
      "8  Completed\n",
      "9  Completed\n",
      "10  Completed\n",
      "11  Completed\n",
      "12  Completed\n",
      "13  Completed\n",
      "14  Completed\n",
      "15  Completed\n",
      "16  Completed\n",
      "17  Completed\n",
      "18  Completed\n",
      "19  Completed\n",
      "20  Completed\n",
      "21  Completed\n",
      "22  Completed\n",
      "23  Completed\n",
      "24  Completed\n",
      "25  Completed\n",
      "26  Completed\n",
      "27  Completed\n",
      "28  Completed\n",
      "29  Completed\n",
      "30  Completed\n",
      "31  Completed\n",
      "32  Completed\n",
      "33  Completed\n",
      "34  Completed\n",
      "35  Completed\n",
      "36  Completed\n",
      "37  Completed\n",
      "38  Completed\n",
      "39  Completed\n",
      "40  Completed\n",
      "41  Completed\n",
      "42  Completed\n",
      "43  Completed\n"
     ]
    }
   ],
   "source": [
    "# File path to your cookies file\n",
    "cookies_file = \"linkedincookies.pkl\"\n",
    "\n",
    "# Specify job title, location, and number of results\n",
    "job_title = \"Data Scientist\"\n",
    "location = \"Kerala\"\n",
    "num_results = 150\n",
    "\n",
    "# Scrape job listings\n",
    "jobs_data = scrape_linkedin_jobs(driver, job_title, location, num_results, cookies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Post Url</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead II - Data Science</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4010427039/...</td>\n",
       "      <td>UST</td>\n",
       "      <td>Trivandrum, Kerala, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead I - ML Engineering</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3942153579/...</td>\n",
       "      <td>UST</td>\n",
       "      <td>Trivandrum, Kerala, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY - GDS Consulting - AI and DATA - Databricks...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4009850434/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kochi, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data and Applied Scientist II</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3977751872/...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Kerala, India (Hybrid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EY - GDS Consulting - AI and DATA -MDM - Senior</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3999068990/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kanayannur, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EY-GDS Consulting-AI And DATA-Data Modeler-Senior</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3998575461/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kanayannur, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data &amp; Applied Scientist Ii</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4014560843/...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Kerala, India (Hybrid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAP Data Science-Senior</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4003042459/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Trivandrum, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EY - GDS Consulting - AI and DATA - Databricks...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4010617146/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Trivandrum, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY - GDS Consulting - AI and DATA - Azure DE -...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4015789194/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kanayannur, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EY-GDS Consulting-AI And DATA-Delivery Lead Cl...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3998573634/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kochi, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4007695150/...</td>\n",
       "      <td>Future Solution Centre</td>\n",
       "      <td>Kollam, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3972897345/...</td>\n",
       "      <td>Norstella</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Data Scientist - LLM Project</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4022370271/...</td>\n",
       "      <td>YO HR Consultancy</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr.Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4008256728/...</td>\n",
       "      <td>ARRISE powering Pragmatic Play</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EY-GDS Consulting-AI And DATA-Delivery Lead Cl...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3998577026/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Trivandrum, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY - GDS Consulting - AI and DATA - ASEAN Solu...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4009433877/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Trivandrum, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist-Kochi</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3907292362/...</td>\n",
       "      <td>Owen Mitten Private Limited</td>\n",
       "      <td>Kochi, Kerala, India (Hybrid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Technical Lead</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4001374424/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Trivandrum, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EY - GDS Consulting - AI and DATA - ASEAN Solu...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4009438055/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kanayannur, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Computer Vision</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3981396878/...</td>\n",
       "      <td>ThreeV Technologies, Inc.</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3930139964/...</td>\n",
       "      <td>Apollo.io</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist(INDIA ONLY)</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4007049332/...</td>\n",
       "      <td>FuturePath AI</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist Mentor</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4020637909/...</td>\n",
       "      <td>GUVI Geek Networks, IITM Research Park</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3916634714/...</td>\n",
       "      <td>Indisquad</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3955753066/...</td>\n",
       "      <td>CONNECTING 2 WORK</td>\n",
       "      <td>Thiruvananthapuram, Kerala, India (Hybrid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Associate - SAS and Python</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4010808155/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kanayannur, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4022367437/...</td>\n",
       "      <td>YO HR Consultancy</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4022368409/...</td>\n",
       "      <td>YO HR Consultancy</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remote Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979761319/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst Analysis - 2024 Batch Just Passou...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4023920771/...</td>\n",
       "      <td>Sparkmetrics Solutions</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remote Data Scientist - Python</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979762455/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remote Python Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979762539/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EY - GDS Consulting - AI and DATA - Databricks...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4009849426/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Trivandrum, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Associate Director-AI and ML</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3989394404/...</td>\n",
       "      <td>EY</td>\n",
       "      <td>Kanayannur, Kerala, India (On-site)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remote Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979756967/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remote Data Scientist - Python</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979758742/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remote Data Scientist - Python</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979757764/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remote Data Scientist - Python</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979756908/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remote Data Scientist</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979756882/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Remote Data Scientist - Python</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979756873/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Remote Data Scientist - Python</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3979761328/...</td>\n",
       "      <td>Turing</td>\n",
       "      <td>India (Remote)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                             Lead II - Data Science   \n",
       "1                            Lead I - ML Engineering   \n",
       "2  EY - GDS Consulting - AI and DATA - Databricks...   \n",
       "3                      Data and Applied Scientist II   \n",
       "4    EY - GDS Consulting - AI and DATA -MDM - Senior   \n",
       "5  EY-GDS Consulting-AI And DATA-Data Modeler-Senior   \n",
       "6                        Data & Applied Scientist Ii   \n",
       "0                            SAP Data Science-Senior   \n",
       "1  EY - GDS Consulting - AI and DATA - Databricks...   \n",
       "2  EY - GDS Consulting - AI and DATA - Azure DE -...   \n",
       "3  EY-GDS Consulting-AI And DATA-Delivery Lead Cl...   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                Python Data Scientist - LLM Project   \n",
       "0                                  Sr.Data Scientist   \n",
       "1  EY-GDS Consulting-AI And DATA-Delivery Lead Cl...   \n",
       "2  EY - GDS Consulting - AI and DATA - ASEAN Solu...   \n",
       "3                               Data Scientist-Kochi   \n",
       "4                                  AI Technical Lead   \n",
       "5  EY - GDS Consulting - AI and DATA - ASEAN Solu...   \n",
       "6                     Data Scientist Computer Vision   \n",
       "0                   Senior Machine Learning Engineer   \n",
       "1                         Data Scientist(INDIA ONLY)   \n",
       "2                              Data Scientist Mentor   \n",
       "3                                 Sr. Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                         Associate - SAS and Python   \n",
       "6                                Lead Data Scientist   \n",
       "0                                Lead Data Scientist   \n",
       "1                              Remote Data Scientist   \n",
       "2  Data Analyst Analysis - 2024 Batch Just Passou...   \n",
       "3                     Remote Data Scientist - Python   \n",
       "4                       Remote Python Data Scientist   \n",
       "5  EY - GDS Consulting - AI and DATA - Databricks...   \n",
       "6                       Associate Director-AI and ML   \n",
       "0                              Remote Data Scientist   \n",
       "1                     Remote Data Scientist - Python   \n",
       "2                     Remote Data Scientist - Python   \n",
       "3                     Remote Data Scientist - Python   \n",
       "4                              Remote Data Scientist   \n",
       "5                     Remote Data Scientist - Python   \n",
       "6                     Remote Data Scientist - Python   \n",
       "\n",
       "                                        Job Post Url  \\\n",
       "0  https://www.linkedin.com/jobs/view/4010427039/...   \n",
       "1  https://www.linkedin.com/jobs/view/3942153579/...   \n",
       "2  https://www.linkedin.com/jobs/view/4009850434/...   \n",
       "3  https://www.linkedin.com/jobs/view/3977751872/...   \n",
       "4  https://www.linkedin.com/jobs/view/3999068990/...   \n",
       "5  https://www.linkedin.com/jobs/view/3998575461/...   \n",
       "6  https://www.linkedin.com/jobs/view/4014560843/...   \n",
       "0  https://www.linkedin.com/jobs/view/4003042459/...   \n",
       "1  https://www.linkedin.com/jobs/view/4010617146/...   \n",
       "2  https://www.linkedin.com/jobs/view/4015789194/...   \n",
       "3  https://www.linkedin.com/jobs/view/3998573634/...   \n",
       "4  https://www.linkedin.com/jobs/view/4007695150/...   \n",
       "5  https://www.linkedin.com/jobs/view/3972897345/...   \n",
       "6  https://www.linkedin.com/jobs/view/4022370271/...   \n",
       "0  https://www.linkedin.com/jobs/view/4008256728/...   \n",
       "1  https://www.linkedin.com/jobs/view/3998577026/...   \n",
       "2  https://www.linkedin.com/jobs/view/4009433877/...   \n",
       "3  https://www.linkedin.com/jobs/view/3907292362/...   \n",
       "4  https://www.linkedin.com/jobs/view/4001374424/...   \n",
       "5  https://www.linkedin.com/jobs/view/4009438055/...   \n",
       "6  https://www.linkedin.com/jobs/view/3981396878/...   \n",
       "0  https://www.linkedin.com/jobs/view/3930139964/...   \n",
       "1  https://www.linkedin.com/jobs/view/4007049332/...   \n",
       "2  https://www.linkedin.com/jobs/view/4020637909/...   \n",
       "3  https://www.linkedin.com/jobs/view/3916634714/...   \n",
       "4  https://www.linkedin.com/jobs/view/3955753066/...   \n",
       "5  https://www.linkedin.com/jobs/view/4010808155/...   \n",
       "6  https://www.linkedin.com/jobs/view/4022367437/...   \n",
       "0  https://www.linkedin.com/jobs/view/4022368409/...   \n",
       "1  https://www.linkedin.com/jobs/view/3979761319/...   \n",
       "2  https://www.linkedin.com/jobs/view/4023920771/...   \n",
       "3  https://www.linkedin.com/jobs/view/3979762455/...   \n",
       "4  https://www.linkedin.com/jobs/view/3979762539/...   \n",
       "5  https://www.linkedin.com/jobs/view/4009849426/...   \n",
       "6  https://www.linkedin.com/jobs/view/3989394404/...   \n",
       "0  https://www.linkedin.com/jobs/view/3979756967/...   \n",
       "1  https://www.linkedin.com/jobs/view/3979758742/...   \n",
       "2  https://www.linkedin.com/jobs/view/3979757764/...   \n",
       "3  https://www.linkedin.com/jobs/view/3979756908/...   \n",
       "4  https://www.linkedin.com/jobs/view/3979756882/...   \n",
       "5  https://www.linkedin.com/jobs/view/3979756873/...   \n",
       "6  https://www.linkedin.com/jobs/view/3979761328/...   \n",
       "\n",
       "                             Company Name  \\\n",
       "0                                     UST   \n",
       "1                                     UST   \n",
       "2                                      EY   \n",
       "3                               Microsoft   \n",
       "4                                      EY   \n",
       "5                                      EY   \n",
       "6                               Microsoft   \n",
       "0                                      EY   \n",
       "1                                      EY   \n",
       "2                                      EY   \n",
       "3                                      EY   \n",
       "4                  Future Solution Centre   \n",
       "5                               Norstella   \n",
       "6                       YO HR Consultancy   \n",
       "0          ARRISE powering Pragmatic Play   \n",
       "1                                      EY   \n",
       "2                                      EY   \n",
       "3             Owen Mitten Private Limited   \n",
       "4                                      EY   \n",
       "5                                      EY   \n",
       "6               ThreeV Technologies, Inc.   \n",
       "0                               Apollo.io   \n",
       "1                           FuturePath AI   \n",
       "2  GUVI Geek Networks, IITM Research Park   \n",
       "3                               Indisquad   \n",
       "4                       CONNECTING 2 WORK   \n",
       "5                                      EY   \n",
       "6                       YO HR Consultancy   \n",
       "0                       YO HR Consultancy   \n",
       "1                                  Turing   \n",
       "2                  Sparkmetrics Solutions   \n",
       "3                                  Turing   \n",
       "4                                  Turing   \n",
       "5                                      EY   \n",
       "6                                      EY   \n",
       "0                                  Turing   \n",
       "1                                  Turing   \n",
       "2                                  Turing   \n",
       "3                                  Turing   \n",
       "4                                  Turing   \n",
       "5                                  Turing   \n",
       "6                                  Turing   \n",
       "\n",
       "                                     Location  \n",
       "0                   Trivandrum, Kerala, India  \n",
       "1                   Trivandrum, Kerala, India  \n",
       "2              Kochi, Kerala, India (On-site)  \n",
       "3                      Kerala, India (Hybrid)  \n",
       "4         Kanayannur, Kerala, India (On-site)  \n",
       "5         Kanayannur, Kerala, India (On-site)  \n",
       "6                      Kerala, India (Hybrid)  \n",
       "0         Trivandrum, Kerala, India (On-site)  \n",
       "1         Trivandrum, Kerala, India (On-site)  \n",
       "2         Kanayannur, Kerala, India (On-site)  \n",
       "3              Kochi, Kerala, India (On-site)  \n",
       "4                               Kollam, India  \n",
       "5                              India (Remote)  \n",
       "6                              India (Remote)  \n",
       "0                              India (Remote)  \n",
       "1         Trivandrum, Kerala, India (On-site)  \n",
       "2         Trivandrum, Kerala, India (On-site)  \n",
       "3               Kochi, Kerala, India (Hybrid)  \n",
       "4         Trivandrum, Kerala, India (On-site)  \n",
       "5         Kanayannur, Kerala, India (On-site)  \n",
       "6                              India (Remote)  \n",
       "0                              India (Remote)  \n",
       "1                              India (Remote)  \n",
       "2                              India (Remote)  \n",
       "3                              India (Remote)  \n",
       "4  Thiruvananthapuram, Kerala, India (Hybrid)  \n",
       "5         Kanayannur, Kerala, India (On-site)  \n",
       "6                              India (Remote)  \n",
       "0                              India (Remote)  \n",
       "1                              India (Remote)  \n",
       "2                              India (Remote)  \n",
       "3                              India (Remote)  \n",
       "4                              India (Remote)  \n",
       "5         Trivandrum, Kerala, India (On-site)  \n",
       "6         Kanayannur, Kerala, India (On-site)  \n",
       "0                              India (Remote)  \n",
       "1                              India (Remote)  \n",
       "2                              India (Remote)  \n",
       "3                              India (Remote)  \n",
       "4                              India (Remote)  \n",
       "5                              India (Remote)  \n",
       "6                              India (Remote)  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReGen",
   "language": "python",
   "name": "regen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
